{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matthewchung74/not_so_blackout/blob/main/SRGAN_blackout.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqLFU_bQvNDJ"
      },
      "source": [
        "## Not so Blackout\n",
        "\n",
        "This notebook demonstrates another technique for blacking out PHI\n",
        "\n",
        "* based on https://colab.research.google.com/drive/1eV9BCLPiBrGllj1vQek2LZkOPuMMZPXa?usp=sharing\n",
        "\n",
        "* first check gpu. things will run best on a `V100`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W30b-LzEJBTR"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXXZPdXXO0Gs"
      },
      "outputs": [],
      "source": [
        "!pip install Faker -Uq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSE2Z6wvHm6C"
      },
      "source": [
        "### Mount drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8N0MDIqIA4l"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxnC49i4HQF9"
      },
      "source": [
        "### Crapify images\n",
        "\n",
        "Set directories in drive and thenadd text to images to crapify them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmnGRzlI_WX1"
      },
      "outputs": [],
      "source": [
        "my_path = \"/content/drive/MyDrive/data/gan/images/chest_xray\"\n",
        "chest_xray_text = \"/content/drive/MyDrive/data/superres/images/chest_xray_text\"\n",
        "chest_xray_resized = \"/content/drive/MyDrive/data/gan/images/chest_xray_resized\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGjNk1zWIiN1"
      },
      "outputs": [],
      "source": [
        "import faker\n",
        "import os\n",
        "from PIL import Image, ImageDraw, ImageFont, ImageOps\n",
        "from faker import Faker\n",
        "import random\n",
        "\n",
        "fake = Faker()\n",
        "\n",
        "font_dir = \"/usr/share/fonts/truetype/liberation\"\n",
        "fonts =  os.listdir(font_dir)\n",
        "\n",
        "def adding_random_text(img):\n",
        "\n",
        "  #top\n",
        "  font = ImageFont.truetype(f\"{font_dir}/{random.choice(fonts)}\", random.randint(6,14))  \n",
        "  text_layer = Image.new('L', img.size)\n",
        "  draw = ImageDraw.Draw(text_layer)\n",
        "  draw.text( (random.randint(0,img.size[0]*0.5), random.randint(0,5)), fake.name(),  font=font, fill=random.randint(150,255))\n",
        "\n",
        "  rotated_text_layer = text_layer.rotate(0.0+90*random.randint(0,1), expand=1)\n",
        "  img.paste( ImageOps.colorize(rotated_text_layer, (0,0,0), (255, 255,255)), None,  rotated_text_layer)\n",
        "\n",
        "  #bottom\n",
        "  font = ImageFont.truetype(f\"{font_dir}/{random.choice(fonts)}\", random.randint(6,14))  \n",
        "  text_layer = Image.new('L', img.size)\n",
        "  draw = ImageDraw.Draw(text_layer)\n",
        "  draw.text( (random.randint(0,60), img.size[1]-random.randint(20,60)), fake.name(),  font=font, fill=random.randint(150,255))\n",
        "\n",
        "  rotated_text_layer = text_layer.rotate(0.0+90*random.randint(0,1), expand=1)\n",
        "  img.paste( ImageOps.colorize(rotated_text_layer, (0,0,0), (255, 255,255)), None,  rotated_text_layer)\n",
        "\n",
        "  return img\n",
        "\n",
        "# change to generate images\n",
        "if False:\n",
        "  for i, file in enumerate(os.listdir(my_path)):\n",
        "      f_img = my_path+\"/\"+file\n",
        "      d_img = chest_xray_text+\"/\"+file\n",
        "      img = Image.open(f_img)\n",
        "      img = img.convert('RGBA')\n",
        "      img = img.resize((256,256))\n",
        "\n",
        "      side = random.randint(0, 3)\n",
        "      x1 = random.randint(0,25)\n",
        "      y1 = random.randint(0,5)\n",
        "      size = random.randint(6,14)\n",
        "      img = adding_random_text(img).convert('RGB')\n",
        "      img.save(d_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sB8GAHS-HR5c"
      },
      "source": [
        "and view the crapified images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6w6exFlPTGt5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "image_paths = os.listdir(chest_xray_text)[:4]\n",
        "img_arr = []\n",
        "\n",
        "for image_path in image_paths:\n",
        "    img_arr.append(np.asarray(Image.open(f\"{chest_xray_text}/{image_path}\")))\n",
        "\n",
        "fig = plt.figure(figsize=(20., 20.))\n",
        "grid = ImageGrid(fig, 111, \n",
        "                 nrows_ncols=(2, 2),  # creates 2x2 grid of axes\n",
        "                 axes_pad=0.1,  # pad between axes\n",
        "                 )\n",
        "\n",
        "for ax, im in zip(grid, img_arr):\n",
        "    ax.imshow(im)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2Dj71Yl1FQr"
      },
      "source": [
        "### Grab a Model\n",
        "grabbed from https://colab.research.google.com/drive/1eV9BCLPiBrGllj1vQek2LZkOPuMMZPXa?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sldVX8yhDTDp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import math\n",
        "from os import listdir\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "from torchvision.transforms import Compose, RandomCrop, ToTensor, ToPILImage, CenterCrop, Resize\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "from os.path import join\n",
        "from pathlib import Path\n",
        "\n",
        "torch.autograd.set_detect_anomaly(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Dataset objects"
      ],
      "metadata": {
        "id": "l906BVQ6krt-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YS3iHOyl1PJK"
      },
      "outputs": [],
      "source": [
        "UPSCALE_FACTOR = 1\n",
        "CROP_SIZE = 100\n",
        "\n",
        "mean = np.array([0.485, 0.456, 0.406])\n",
        "std = np.array([0.229, 0.224, 0.225])\n",
        "\n",
        "# Now, I will load in some code for the dataset and dataloaders.\n",
        "# Link to this notebook will be in the description, so you can get it from there\n",
        "def is_image_file(filename):\n",
        "    return any(filename.endswith(extension) for extension in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG'])\n",
        "\n",
        "class TrainDatasetFromFolder(Dataset):\n",
        "    # def __init__(self, dataset_dir, crop_size, upscale_factor):\n",
        "    def __init__(self, chest_xray_text, chest_xray_resized):\n",
        "        super(TrainDatasetFromFolder, self).__init__()\n",
        "        self.chest_xray_text_folder = chest_xray_text\n",
        "        self.chest_xray_resized_folder = chest_xray_resized\n",
        "\n",
        "        self.chest_xray_resized = [join(chest_xray_resized, x) for x in listdir(chest_xray_resized) if is_image_file(x)]\n",
        "\n",
        "        print(f\"chest_xray_text_folder: {self.chest_xray_text_folder}\")\n",
        "        print(f\"chest_xray_resized_folder: {self.chest_xray_resized_folder}\")\n",
        "\n",
        "        self.hr_transform = ToTensor()\n",
        "        self.lr_transform = ToTensor()\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        hr_image = self.hr_transform(Image.open(self.chest_xray_resized[index]))\n",
        "        # print(f\"hr_image {hr_image.shape}\")\n",
        "        path = Path(self.chest_xray_resized[index])\n",
        "        lr_image = self.lr_transform(Image.open(f\"{self.chest_xray_text_folder}/{path.name}\"))\n",
        "        # print(f\"lr_image {lr_image.shape}\")\n",
        "        return lr_image, hr_image\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.chest_xray_resized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fSY1Z_h6qit"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 4\n",
        "train_set = TrainDatasetFromFolder(chest_xray_text, chest_xray_resized)\n",
        "trainloader = DataLoader(train_set, batch_size=BATCH_SIZE, num_workers=1, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRBGeQJA6tex"
      },
      "outputs": [],
      "source": [
        "from torch import nn, optim\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "  def __init__(self, channels):\n",
        "    super(ResidualBlock, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
        "    self.bn1 = nn.BatchNorm2d(channels)\n",
        "    self.prelu = nn.PReLU()\n",
        "    self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
        "    self.bn2 = nn.BatchNorm2d(channels)\n",
        "  def forward(self, x):\n",
        "    residual = self.conv1(x)\n",
        "    residual = self.bn1(residual)\n",
        "    residual = self.prelu(residual)\n",
        "    residual = self.conv2(residual)\n",
        "    residual = self.bn2(residual)\n",
        "    return x + residual\n",
        "  \n",
        "class UpsampleBlock(nn.Module):\n",
        "  def __init__(self, in_channels, up_scale):\n",
        "    super(UpsampleBlock, self).__init__()\n",
        "    self.conv = nn.Conv2d(in_channels, in_channels * up_scale ** 2, \n",
        "                          kernel_size=3, padding=1)\n",
        "    self.pixel_shuffle = nn.PixelShuffle(up_scale)\n",
        "    self.prelu = nn.PReLU()\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    x = self.pixel_shuffle(x)\n",
        "    x = self.prelu(x)\n",
        "    return x\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, scale_factor):\n",
        "    super(Generator, self).__init__()\n",
        "    upsample_block_num = int(math.log(scale_factor, 2))\n",
        "\n",
        "    self.block1 = nn.Sequential(\n",
        "        nn.Conv2d(3, 64, kernel_size=9, padding=4),\n",
        "        nn.PReLU()\n",
        "    )\n",
        "\n",
        "    self.block2 = ResidualBlock(64)\n",
        "    self.block3 = ResidualBlock(64)\n",
        "    self.block4 = ResidualBlock(64)\n",
        "    self.block5 = ResidualBlock(64)\n",
        "    self.block6 = ResidualBlock(64)\n",
        "    self.block7 = nn.Sequential(\n",
        "        nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(64)\n",
        "    )\n",
        "    block8 = [UpsampleBlock(64, 2) for _ in range(upsample_block_num)]\n",
        "    block8.append(nn.Conv2d(64, 3, kernel_size=9, padding=4))\n",
        "    self.block8 = nn.Sequential(*block8)\n",
        "  def forward(self, x):\n",
        "    block1 = self.block1(x)\n",
        "    block2 = self.block2(block1)\n",
        "    block3 = self.block3(block2)\n",
        "    block4 = self.block4(block3)\n",
        "    block5 = self.block5(block4)\n",
        "    block6 = self.block6(block5)\n",
        "    block7 = self.block7(block6)\n",
        "    block8 = self.block8(block1 + block7)\n",
        "    return (torch.tanh(block8) + 1) / 2\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.AdaptiveAvgPool2d(1),\n",
        "        nn.Conv2d(512, 1024, kernel_size=1),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Conv2d(1024, 1, kernel_size=1)\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    batch_size=x.size()[0]\n",
        "    return torch.sigmoid(self.net(x).view(batch_size))\n",
        "\n",
        "from torchvision.models.vgg import vgg16\n",
        "\n",
        "# Now we got to make the Generator Loss\n",
        "class TVLoss(nn.Module):\n",
        "  def __init__(self, tv_loss_weight=1):\n",
        "    super(TVLoss, self).__init__()\n",
        "    self.tv_loss_weight=tv_loss_weight\n",
        "  def forward(self, x):\n",
        "    batch_size=x.size()[0]\n",
        "    h_x = x.size()[2]\n",
        "    w_x = x.size()[3]\n",
        "\n",
        "    count_h = self.tensor_size(x[:, :, 1:, :])\n",
        "    count_w = self.tensor_size(x[:, :, :, 1:])\n",
        "\n",
        "    h_tv = torch.pow(x[:, :, 1:, :] - x[:, :, :h_x - 1, :], 2).sum()\n",
        "    w_tv = torch.pow(x[:, :, :, 1:] - x[:, :, :, :w_x - 1], 2).sum()\n",
        "    return self.tv_loss_weight * 2 * (h_tv / count_h + w_tv / count_w) / batch_size\n",
        "  \n",
        "  # Forgot to implement an important method\n",
        "  @staticmethod # Must add this\n",
        "  def tensor_size(t):\n",
        "    return t.size()[1] * t.size()[2] * t.size()[3]\n",
        "\n",
        "class GeneratorLoss(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(GeneratorLoss, self).__init__()\n",
        "    vgg = vgg16(pretrained=True)\n",
        "    loss_network = nn.Sequential(*list(vgg.features)[:31]).eval()\n",
        "    for param in loss_network.parameters():\n",
        "      param.requires_grad = False\n",
        "    self.loss_network = loss_network\n",
        "    self.mse_loss = nn.MSELoss()\n",
        "    self.tv_loss = TVLoss()\n",
        "  def forward(self, out_labels, out_images, target_images):\n",
        "    adversial_loss = torch.mean(1 - out_labels)\n",
        "    perception_loss = self.mse_loss(out_images, target_images)\n",
        "    image_loss = self.mse_loss(out_images, target_images)\n",
        "    tv_loss = self.tv_loss(out_images)\n",
        "    return image_loss + 0.001 * adversial_loss + 0.006 * perception_loss + 2e-8 * tv_loss\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32t34WIIAPlD"
      },
      "outputs": [],
      "source": [
        "device  = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iz9URoPfAQzy"
      },
      "outputs": [],
      "source": [
        "netG = Generator(UPSCALE_FACTOR)\n",
        "netD = Discriminator()\n",
        "generator_criterion = GeneratorLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BY0BjpKxAyaj"
      },
      "outputs": [],
      "source": [
        "generator_criterion = generator_criterion.to(device)\n",
        "netG = netG.to(device)\n",
        "netD = netD.to(device)\n",
        "\n",
        "N_EPOCHS = 150 \n",
        "LR = 0.0002\n",
        "\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=LR)\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=LR)\n",
        "\n",
        "results = {\n",
        "    \"d_loss\":[],\n",
        "    \"g_loss\":[],\n",
        "    \"d_score\": [],\n",
        "    \"g_score\": []\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjfMR10IA4Mz"
      },
      "outputs": [],
      "source": [
        "## Now for training code\n",
        "from tqdm import tqdm\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "xoWJmh8llAEi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "b_WcMz6YA572"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as T\n",
        "\n",
        "def save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n",
        "    print(f\"Saving checkpoint {filename}\")\n",
        "    checkpoint = {\n",
        "        \"state_dict\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "    }\n",
        "    torch.save(checkpoint, filename)\n",
        "\n",
        "def test_rand_image(saved_pil_path):\n",
        "  random_file = random.choice(os.listdir(chest_xray_resized))\n",
        "  random_path = chest_xray_resized+\"/\"+random_file\n",
        "  random_image_text = adding_random_text(Image.open(random_path))\n",
        "  random_image = ToTensor()(random_image_text).to(device)\n",
        "  random_image = random_image[None, :]\n",
        "  random_processed_image = netG(random_image)\n",
        "\n",
        "  cated = torch.cat((random_image.squeeze(), random_processed_image.squeeze()), 1)\n",
        "  pil_image = T.ToPILImage()(cated)\n",
        "  display(pil_image)\n",
        "  pil_image.save(saved_pil_path)\n",
        "\n",
        "\n",
        "for epoch in range(1, N_EPOCHS + 1):\n",
        "  train_bar = tqdm(trainloader)\n",
        "  running_results = {'batch_sizes':0, 'd_loss':0,\n",
        "                     \"g_loss\":0, \"d_score\":0, \"g_score\":0}\n",
        "\n",
        "  ctr = 0\n",
        "  netG.train()\n",
        "  netD.train()\n",
        "  for data, target in train_bar:\n",
        "    g_update_first = True\n",
        "    batch_size = data.size(0)\n",
        "    running_results['batch_sizes'] += batch_size\n",
        "\n",
        "    real_img = Variable(target)\n",
        "    real_img = real_img.to(device)\n",
        "    z = Variable(data)\n",
        "    z = z.to(device)\n",
        "\n",
        "    ## Update Discriminator ##\n",
        "    fake_img = netG(z)\n",
        "    netD.zero_grad()\n",
        "    real_out = netD(real_img).mean()\n",
        "    fake_out = netD(fake_img).mean()\n",
        "    d_loss = 1 - real_out + fake_out\n",
        "    d_loss.backward(retain_graph = True)\n",
        "    optimizerD.step()\n",
        "    \n",
        "    ## Now update Generator\n",
        "    fake_img = netG(z)\n",
        "    fake_out = netD(fake_img).mean()\n",
        "    netG.zero_grad()\n",
        "    g_loss = generator_criterion(fake_out, fake_img, real_img)\n",
        "    g_loss.backward()\n",
        "\n",
        "    fake_img = netG(z)\n",
        "    fake_out = netD(fake_img).mean()\n",
        "\n",
        "    optimizerG.step()\n",
        "\n",
        "    running_results['g_loss'] += g_loss.item() * batch_size\n",
        "    running_results['d_loss'] += d_loss.item() * batch_size\n",
        "    running_results['d_score'] += real_out.item() * batch_size\n",
        "    running_results['g_score'] += real_out.item() * batch_size\n",
        "\n",
        "    ## Updating the progress bar\n",
        "    train_bar.set_description(desc=\"[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f\" % (\n",
        "        epoch, N_EPOCHS, running_results['d_loss'] / running_results['batch_sizes'],\n",
        "        running_results['g_loss'] / running_results['batch_sizes'],\n",
        "        running_results['d_score'] / running_results['batch_sizes'],\n",
        "        running_results['g_score'] / running_results['batch_sizes']\n",
        "    ))\n",
        "\n",
        "  save_checkpoint(netG, optimizerG, f\"/content/drive/MyDrive/data/superres/experiments/g_{epoch}.pth\")    \n",
        "  save_checkpoint(netD, optimizerD, f\"/content/drive/MyDrive/data/superres/experiments/d_{epoch}.pth\")    \n",
        "  netG.eval() \n",
        "  test_rand_image(f\"/content/drive/MyDrive/data/superres/experiments/test_{epoch}.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check your work"
      ],
      "metadata": {
        "id": "gdw3cVEElEHO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCxBlAPgm6fg"
      },
      "outputs": [],
      "source": [
        "def load_checkpoint(checkpoint_file, model, optimizer, lr):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    checkpoint = torch.load(checkpoint_file)\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "\n",
        "epoch = 1\n",
        "inference_netG = Generator(1)\n",
        "load_checkpoint(f\"/content/drive/MyDrive/data/superres/experiments/g_{epoch}.pth\", inference_netG, optimizerG, lr=0.0002)\n",
        "\n",
        "f = random.choice(os.listdir(my_path))\n",
        "d_img = chest_xray_text+\"/\"+f\n",
        "img = Image.open(d_img)\n",
        "img = img.convert('RGBA')\n",
        "img = img.resize((256,256))\n",
        "\n",
        "before_img1 = train_set[0][0]\n",
        "after_img1 = inference_netG( before_img1 )\n",
        "\n",
        "before_img2 = adding_random_text(img).convert('RGB')\n",
        "after_img2 = inference_netG(before_img1)\n",
        "\n",
        "fig = plt.figure(figsize=(4., 4.))\n",
        "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
        "                 nrows_ncols=(1, 2),  # creates 2x2 grid of axes\n",
        "                 axes_pad=0.1,  # pad between axes in inch.\n",
        "                 )\n",
        "\n",
        "for ax, im in zip(grid, [before_img1, after_img1, before_img2, after_img2]):\n",
        "    ax.imshow(im)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xt5n0u3PboBo"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "not_so_blackout.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNtHxhjrtutx7ncjQDC1/OI",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}